Execution time: 2025-07-02 18:18:15
--------------- args ---------------
save_root : ./results/20250702_agnews_re
gpu_id : 0
seed : 0
data_type_name : auto
model : Bert-base#pretrain
dataset : custom-agnews_all-bert_base
data_path : ./datasets/custom-agnews_all-bert_base
batch_size : 1
data_split : test
interaction_type : re
selected_dim : gt-log-odds
gt_type : correct
player_path : ./players/custom-agnews_all-bert_base
baseline_type : unk
baseline_path : 
background_type : ori
sort_type : order
cal_batch_size : 256
verbose : 1
start_sample : 0
sample_batch_size : 10
max_sample_num : None
device : cuda:0
dataset_model : dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0
save_path : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#
save_path_result : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#\data
save_path_log : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#\log
arch : Bert-base
model_kwargs : {'num_labels': 4}
tokenizer_kwargs : {}
ModelClass : <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>
TokenizerClass : <class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>
config_path : src/models/nlp/configs/bert-base_config.json
task : nlp-seq-cls
DatasetClass : <class 'src.data.AGNews.AGNews'>
data_type_actual : torch.float32
------------------------------
Numpy: 1.24.4
Pytorch: 2.0.1+cu117
torchvision: 0.15.2+cu117
Cuda: 11.7
hostname: DESKTOP-337C7ME
==================================================
Execution time: 2025-07-02 19:17:23
--------------- args ---------------
save_root : ./results/20250702_agnews_re
gpu_id : 0
seed : 0
data_type_name : auto
model : Bert-base#pretrain
dataset : custom-agnews_all-bert_base
data_path : ./datasets/custom-agnews_all-bert_base
batch_size : 1
data_split : test
interaction_type : re
selected_dim : gt-log-odds
gt_type : correct
player_path : ./players/custom-agnews_all-bert_base
baseline_type : unk
baseline_path : 
background_type : ori
sort_type : order
cal_batch_size : 256
verbose : 1
start_sample : 0
sample_batch_size : 10
max_sample_num : None
device : cuda:0
dataset_model : dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0
save_path : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#
save_path_result : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#\data
save_path_log : ./results/20250702_agnews_re\result\dataset=custom-agnews_all-bert_base-test_model=Bert-base#pretrain_seed=0\players=custom-agnews_all-bert_base_lbl=correct_baseline=unk_bg=ori#\log
arch : Bert-base
model_kwargs : {'num_labels': 4}
tokenizer_kwargs : {}
ModelClass : <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>
TokenizerClass : <class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>
config_path : src/models/nlp/configs/bert-base_config.json
task : nlp-seq-cls
DatasetClass : <class 'src.data.AGNews.AGNews'>
data_type_actual : torch.float32
------------------------------
Numpy: 1.24.4
Pytorch: 2.0.1+cu117
torchvision: 0.15.2+cu117
Cuda: 11.7
hostname: DESKTOP-337C7ME
==================================================
