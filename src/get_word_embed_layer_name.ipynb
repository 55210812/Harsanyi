{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2439784de3a8632c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T12:35:44.949301Z",
     "start_time": "2025-02-14T12:35:41.953801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renqihan/.conda/envs/sae/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "from utils.global_const import *\n",
    "\n",
    "# Set the cache directory for huggingface hub. [Important!] It should be before the import of transformers\n",
    "os.environ[\"HF_HOME\"] = HF_HOME\n",
    "\n",
    "print(os.path.exists(HF_HOME))\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3737b629b71798",
   "metadata": {},
   "source": [
    "**BERTweet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209b7cb",
   "metadata": {},
   "source": [
    "$$I(S) = \\sum_{L\\subseteq S} (-1)^{s-l} v(L)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T12:35:51.006204Z",
     "start_time": "2025-02-14T12:35:49.726250Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "/home/renqihan/.conda/envs/sae/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/renqihan/.conda/envs/sae/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# BERTweet\n",
    "tokenizer_bertweet = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "model_bertweet = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ee78651cfa029c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T12:37:14.034716Z",
     "start_time": "2025-02-14T12:37:14.026516Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(model_bertweet.roberta.embeddings.word_embeddings._modules.keys()) # roberta/embeddings/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332e6b0d233b5f8",
   "metadata": {},
   "source": [
    "**OPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66867f57856381a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:50:18.531707Z",
     "start_time": "2025-01-10T16:49:56.394254500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5368449ee00446afac077605729323bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  55%|#####4    | 1.43G/2.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OPT\n",
    "tokenizer_opt = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "model_opt = AutoModelForCausalLM.from_pretrained(\"facebook/opt-1.3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6030920a2079203e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:05:22.323989Z",
     "start_time": "2025-01-10T17:05:22.301805Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embed_tokens', 'embed_positions', 'final_layer_norm', 'layers'])\n"
     ]
    }
   ],
   "source": [
    "print(model_opt.model.decoder._modules.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42bd27943fe79df",
   "metadata": {},
   "source": [
    "**Pythia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6596d82be9fd300a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:45:33.786943Z",
     "start_time": "2025-01-21T02:45:32.470553Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM\n",
    "\n",
    "# Pythia\n",
    "model_size = \"70m\"\n",
    "model_pythia = GPTNeoXForCausalLM.from_pretrained(f\"EleutherAI/pythia-{model_size}\")\n",
    "tokenizer_pythia = AutoTokenizer.from_pretrained(f\"EleutherAI/pythia-{model_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933024c15bf7820d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:41:53.272086Z",
     "start_time": "2025-01-21T02:41:53.264118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embed_in', 'emb_dropout', 'layers', 'final_layer_norm'])\n"
     ]
    }
   ],
   "source": [
    "print(model_pythia.gpt_neox._modules.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a534ceef2bf37d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:43:18.029308Z",
     "start_time": "2025-01-21T02:43:18.020499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model_pythia.gpt_neox.embed_in == model_pythia.get_input_embeddings())\n",
    "print(model_pythia.gpt_neox.embed_in == model_pythia._modules[\"gpt_neox\"]._modules[\"embed_in\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967d6031ed61789",
   "metadata": {},
   "source": [
    "**Qwen2.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83c6975518e455e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T12:11:09.360123Z",
     "start_time": "2025-02-12T12:10:59.942154Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Qwen\n",
    "model_qwen = AutoModelForCausalLM.from_pretrained(f\"Qwen/Qwen2.5-14B\", torch_dtype='auto')\n",
    "tokenizer_qwen = AutoTokenizer.from_pretrained(f\"Qwen/Qwen2.5-14B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264e141d26d3bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T12:11:10.120232Z",
     "start_time": "2025-02-12T12:11:10.112433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(model_qwen.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790e95dfca34c231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T03:46:40.450369Z",
     "start_time": "2025-02-08T03:46:40.443890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embed_tokens', 'layers', 'norm'])\n"
     ]
    }
   ],
   "source": [
    "print(model_qwen.model._modules.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7ac5e504898a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T03:46:41.624109Z",
     "start_time": "2025-02-08T03:46:41.620394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(152064, 5120)\n"
     ]
    }
   ],
   "source": [
    "print(model_qwen.model.embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4cc2e78f5f9401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T11:13:28.803620Z",
     "start_time": "2025-02-05T11:13:28.517405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(model_qwen.dtype)\n",
    "prompt = \"Hello world. Good morning.\"\n",
    "inputs = tokenizer_qwen(prompt, return_tensors='pt')\n",
    "outputs = model_qwen(**inputs, return_dict=True, output_hidden_states=True)\n",
    "print(outputs.logits.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
