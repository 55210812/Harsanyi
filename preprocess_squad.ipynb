{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd744c8d2b219ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:12:19.331915Z",
     "start_time": "2025-02-03T03:10:46.111649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renqihan/.conda/envs/sae/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sympy.codegen.ast import continue_\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from utils.global_const import *\n",
    "\n",
    "# Set the cache directory for huggingface hub. [Important!] It should be before the import of transformers\n",
    "os.environ[\"HF_HOME\"] = HF_HOME\n",
    "\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from utils import save_json\n",
    "from interaction.player import get_invalid_words, get_all_punctuations\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = \"rajpurkar/squad\"\n",
    "train_set_raw = load_dataset(dataset_name, split='train') \n",
    "val_set_raw = load_dataset(dataset_name, split='validation')\n",
    "# ('id', 'title', 'context', 'question', 'answers')\n",
    "\n",
    "all_punctuations = get_all_punctuations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b160a67699599bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:12:45.791996Z",
     "start_time": "2025-02-03T03:12:45.572227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18891\n",
      "2067\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_list(lst): # deduplicate while keeping the order\n",
    "    return list(dict.fromkeys(lst))\n",
    "\n",
    "train_context = deduplicate_list(train_set_raw['context'])\n",
    "val_context = deduplicate_list(val_set_raw['context'])\n",
    "print(len(train_context))\n",
    "print(len(val_context))\n",
    "\n",
    "# randomly shuffle the context list\n",
    "seed = 0\n",
    "np.random.RandomState(seed).shuffle(train_context)\n",
    "np.random.RandomState(seed).shuffle(val_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041825b2f141073",
   "metadata": {},
   "source": [
    "**20250126 custom-squad-v1** -> **v2 (bug fix)**\n",
    "\n",
    "1. v1用的是set进行deduplication，v2用的是dict，set有可能会打乱顺序且无法复现。\n",
    "\n",
    "2. 另外v2还用了shuffle，打乱了context的顺序。\n",
    "\n",
    "3. v2要求predicted word第一个字符不能是标点符号。\n",
    "\n",
    "4. 把punctuation的范围从ascii_punctuation扩展到unicode_punctuation。\n",
    "\n",
    "5. v2要求predicted word前一个词不能是invalid word，不然这个invalid word会一直作为background存在，有可能导致 v(空) 过大 以及 v(N) - v(空) 过小。 一个典型例子是 at least 这个词组，在at这个词存在时，least的预测概率本身就会大大增加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3d8ecee7e10cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:12:53.469531Z",
     "start_time": "2025-02-03T03:12:53.446282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes,\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def strip_punctuation(word, punc_list=all_punctuations):\n",
    "    \"\"\"\n",
    "    This function is used to strip the punctuation from the beginning and end of a word.\n",
    "    \"\"\"\n",
    "    return re.sub('^[{0}]+|[{0}]+$'.format(punc_list), '', word)\n",
    "\n",
    "def detect_punctuation(word, punc_list=all_punctuations):\n",
    "    \"\"\"\n",
    "    This function is used to detect whether there are at least one punctuation at the beginning or end of a word.\n",
    "    \"\"\"\n",
    "    if word[0] in punc_list or word[-1] in punc_list:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "word_test_ = \"yes,\"\n",
    "# word_test_ = \"./;'[]//\"\n",
    "print(strip_punctuation(word_test_))\n",
    "print(detect_punctuation(word_test_, punc_list=['.', ';', ',']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87435e8e70ea39be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:12:56.754351Z",
     "start_time": "2025-02-03T03:12:56.739927Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NUM_PLAYERS_MAX = 12\n",
    "POS_NO_PUNC = 3\n",
    "SEP_PUNCS = ['.', ';', ',']\n",
    "\n",
    "def check_precede_punc(context_words, curr_index):\n",
    "    # try:\n",
    "    for j in range(1, POS_NO_PUNC + 1):\n",
    "        if detect_punctuation(context_words[curr_index - j], punc_list=SEP_PUNCS):\n",
    "            # print(\"precede punc detected\")\n",
    "            return True\n",
    "    return False\n",
    "    # except IndexError:\n",
    "    #     print(\"context_words: \", context_words)\n",
    "    #     return False\n",
    "\n",
    "def get_sentences_v1_20250126(context_list, invalid_words):\n",
    "    sentence_list = []\n",
    "    next_word_list = []\n",
    "    player_words_list = []\n",
    "    for idx, context in tqdm(enumerate(context_list)):\n",
    "        # if idx not in [97,98,99,100,101]:\n",
    "        #     continue\n",
    "        # print(f\"idx: {idx}\")\n",
    "\n",
    "        # 换行符替换为空格\n",
    "        context = context.replace('\\n', ' ')\n",
    "        # 多个空格替换为一个空格\n",
    "        context = re.sub(r'\\s+', ' ', context)\n",
    "        context_words = context.split(' ')\n",
    "\n",
    "        num_valid_words = 0\n",
    "        player_words = []\n",
    "        # print(\"context_words:\", context_words)\n",
    "        for i in range(len(context_words)): # start from 0\n",
    "\n",
    "            word = context_words[i]\n",
    "            word_strip_punc = strip_punctuation(word.lower())\n",
    "            if word_strip_punc not in invalid_words and word_strip_punc != '':\n",
    "                num_valid_words += 1\n",
    "                player_words.append(word)\n",
    "\n",
    "            if num_valid_words == NUM_PLAYERS_MAX + 1 or i == len(context_words) - 1:\n",
    "                # print(\"no valid sentence when num_valid_words == NUM_PLAYERS_MAX + 1, or when i == len(context_words) - 1\")\n",
    "                break\n",
    "\n",
    "            if num_valid_words == NUM_PLAYERS_MAX:\n",
    "                next_word = context_words[i + 1]\n",
    "                # print(f\"next_word: {next_word}\")\n",
    "                # print(f\"next_word[0]: {next_word[0]}\")\n",
    "\n",
    "                next_word_strip_punc = strip_punctuation(next_word.lower())\n",
    "                if check_precede_punc(context_words, i + 1) or next_word_strip_punc in invalid_words or next_word_strip_punc == '' or next_word[0] in all_punctuations: # v1这里是i, 但是应该是i+1， v2已经修复\n",
    "                    # print(\"precede punc detected or next word is invalid\")\n",
    "                    # continue\n",
    "                    break # v2从continue改为break，要求predicted word前面一个词不能是invalid word\n",
    "                else:\n",
    "                    # print(\"i=\", i)\n",
    "                    # print(\"context_words[:i]\", context_words[:i])\n",
    "                    # print(\"next_word: \", next_word)\n",
    "                    sentence = ' '.join(context_words[:i + 1]) # include the current word\n",
    "                    sentence_list.append(sentence)\n",
    "                    next_word_list.append(next_word)\n",
    "                    player_words_list.append(player_words)\n",
    "                    break\n",
    "\n",
    "    return sentence_list, next_word_list, player_words_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c54461ca8b0045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:13:55.204319Z",
     "start_time": "2025-02-03T03:12:59.972417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18891it [00:49, 381.39it/s]\n",
      "2067it [00:05, 386.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Humanistic psychology is a psychological perspective which rose to prominence in the mid-20th century in response to Sigmund Freud's psychoanalytic\n",
      "next_word: theory\n",
      "player_words: ['Humanistic', 'psychology', 'psychological', 'perspective', 'rose', 'prominence', 'mid-20th', 'century', 'response', 'Sigmund', \"Freud's\", 'psychoanalytic']\n",
      "sentence: Federalism has a long tradition in German history. The Holy Roman Empire comprised many petty states\n",
      "next_word: numbering\n",
      "player_words: ['Federalism', 'long', 'tradition', 'German', 'history.', 'Holy', 'Roman', 'Empire', 'comprised', 'many', 'petty', 'states']\n",
      "sentence: 122nd Street is mentioned in the movie Taxi Driver by main character Travis Bickle as the location where a fellow\n",
      "next_word: cab\n",
      "player_words: ['122nd', 'Street', 'mentioned', 'movie', 'Taxi', 'Driver', 'main', 'character', 'Travis', 'Bickle', 'location', 'fellow']\n",
      "sentence: In response to the pressure on Hot AC, a new kind of AC format cropped up among American radio\n",
      "next_word: recently.\n",
      "player_words: ['response', 'pressure', 'Hot', 'AC,', 'new', 'kind', 'AC', 'format', 'cropped', 'among', 'American', 'radio']\n",
      "sentence: The Edwardian era in the United Kingdom is the period spanning the reign of King Edward VII up to the end of the First\n",
      "next_word: World\n",
      "player_words: ['Edwardian', 'era', 'United', 'Kingdom', 'period', 'spanning', 'reign', 'King', 'Edward', 'VII', 'end', 'First']\n",
      "sentence: In March 2012, Sony Music reportedly closed its Philippines office due to piracy, causing to move\n",
      "next_word: distribution\n",
      "player_words: ['March', '2012,', 'Sony', 'Music', 'reportedly', 'closed', 'Philippines', 'office', 'due', 'piracy,', 'causing', 'move']\n",
      "sentence: Cardinal priests are the most numerous of the three orders of cardinals in the Catholic Church, ranking above the cardinal deacons and below the cardinal\n",
      "next_word: bishops.\n",
      "player_words: ['Cardinal', 'priests', 'numerous', 'three', 'orders', 'cardinals', 'Catholic', 'Church,', 'ranking', 'cardinal', 'deacons', 'cardinal']\n",
      "sentence: Apple's Safari had its first beta release in January 2003; as of April 2011, it had a dominant share of Apple-based\n",
      "next_word: web\n",
      "player_words: [\"Apple's\", 'Safari', 'first', 'beta', 'release', 'January', '2003;', 'April', '2011,', 'dominant', 'share', 'Apple-based']\n",
      "sentence: A cappella [a kapˈpɛlla] (Italian for \"in the manner of the chapel\") music is specifically group or solo singing\n",
      "next_word: without\n",
      "player_words: ['cappella', '[a', 'kapˈpɛlla]', '(Italian', '\"in', 'manner', 'chapel\")', 'music', 'specifically', 'group', 'solo', 'singing']\n",
      "sentence: The central oscillator generates a self-sustaining rhythm and is driven by two interacting feedback loops that are active at different\n",
      "next_word: times\n",
      "player_words: ['central', 'oscillator', 'generates', 'self-sustaining', 'rhythm', 'driven', 'two', 'interacting', 'feedback', 'loops', 'active', 'different']\n",
      "=====================================\n",
      "sentence: Endosymbiotic gene transfer is how we know about the lost chloroplasts in many chromalveolate lineages. Even if a chloroplast is eventually\n",
      "next_word: lost,\n",
      "player_words: ['Endosymbiotic', 'gene', 'transfer', 'know', 'lost', 'chloroplasts', 'many', 'chromalveolate', 'lineages.', 'Even', 'chloroplast', 'eventually']\n",
      "sentence: Near the end of his life, Tesla walked to the park every day to feed the pigeons and even brought\n",
      "next_word: injured\n",
      "player_words: ['Near', 'end', 'life,', 'Tesla', 'walked', 'park', 'every', 'day', 'feed', 'pigeons', 'even', 'brought']\n",
      "sentence: But bounding the computation time above by some concrete function f(n) often yields complexity classes that depend on the chosen\n",
      "next_word: machine\n",
      "player_words: ['bounding', 'computation', 'time', 'concrete', 'function', 'f(n)', 'often', 'yields', 'complexity', 'classes', 'depend', 'chosen']\n",
      "sentence: In many poor and developing countries much land and housing is held outside the formal or legal property\n",
      "next_word: ownership\n",
      "player_words: ['many', 'poor', 'developing', 'countries', 'much', 'land', 'housing', 'held', 'outside', 'formal', 'legal', 'property']\n",
      "sentence: Throughout the 18th century, Enlightenment ideas of the power of reason and free will became widespread among Congregationalist\n",
      "next_word: ministers,\n",
      "player_words: ['Throughout', '18th', 'century,', 'Enlightenment', 'ideas', 'power', 'reason', 'free', 'became', 'widespread', 'among', 'Congregationalist']\n",
      "sentence: During this time, the discovery of oil in the North Sea and the following \"It's Scotland's oil\" campaign of the Scottish National\n",
      "next_word: Party\n",
      "player_words: ['time,', 'discovery', 'oil', 'North', 'Sea', 'following', '\"It\\'s', \"Scotland's\", 'oil\"', 'campaign', 'Scottish', 'National']\n",
      "sentence: The IPCC concentrates its activities on the tasks allotted to it by the relevant WMO Executive Council and UNEP Governing Council\n",
      "next_word: resolutions\n",
      "player_words: ['IPCC', 'concentrates', 'activities', 'tasks', 'allotted', 'relevant', 'WMO', 'Executive', 'Council', 'UNEP', 'Governing', 'Council']\n",
      "sentence: The Education Service Contracting scheme of the government provides financial assistance for tuition and other school fees of students\n",
      "next_word: turned\n",
      "player_words: ['Education', 'Service', 'Contracting', 'scheme', 'government', 'provides', 'financial', 'assistance', 'tuition', 'school', 'fees', 'students']\n",
      "sentence: Parliamentary time is also set aside for question periods in the debating chamber. A \"General Question Time\"\n",
      "next_word: takes\n",
      "player_words: ['Parliamentary', 'time', 'also', 'set', 'aside', 'question', 'periods', 'debating', 'chamber.', '\"General', 'Question', 'Time\"']\n",
      "sentence: In the August 1917 edition of the magazine Electrical Experimenter Tesla postulated that electricity could be used to locate\n",
      "next_word: submarines\n",
      "player_words: ['August', '1917', 'edition', 'magazine', 'Electrical', 'Experimenter', 'Tesla', 'postulated', 'electricity', 'could', 'used', 'locate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_words = get_invalid_words()\n",
    "sentence_list_train, next_word_list_train, player_words_list_train = get_sentences_v1_20250126(train_context, invalid_words)\n",
    "sentence_list_val, next_word_list_val, player_words_list_val = get_sentences_v1_20250126(val_context, invalid_words)\n",
    "\n",
    "for idx in range(10):\n",
    "    print(\"sentence:\", sentence_list_train[idx])\n",
    "    print(\"next_word:\", next_word_list_train[idx])\n",
    "    print(\"player_words:\", player_words_list_train[idx])\n",
    "print(\"=====================================\")\n",
    "for idx in range(10):\n",
    "    print(\"sentence:\", sentence_list_val[idx])\n",
    "    print(\"next_word:\", next_word_list_val[idx])\n",
    "    print(\"player_words:\", player_words_list_val[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424dbff6e98e4e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T03:17:03.892353Z",
     "start_time": "2025-02-03T03:17:03.798363Z"
    }
   },
   "outputs": [],
   "source": [
    "# save_dir_name_train = \"custom-squad-v1-20250126-train\"\n",
    "# save_dir_name_val = \"custom-squad-v1-20250126-val\"\n",
    "save_dir_name_train = \"custom-squad-v2-20250202-train\"\n",
    "save_dir_name_val = \"custom-squad-v2-20250202-val\"\n",
    "\n",
    "player_dir_name_list = [\n",
    "    \"players-pythia\",\n",
    "    \"players-qwen\",\n",
    "]\n",
    "\n",
    "os.makedirs(f\"../datasets/{save_dir_name_train}\", exist_ok=True)\n",
    "os.makedirs(f\"../datasets/{save_dir_name_val}\", exist_ok=True)\n",
    "\n",
    "# write sentences into a txt file\n",
    "with open(f\"../datasets/{save_dir_name_train}/sentences.txt\", \"w\") as f:\n",
    "    for sentence in sentence_list_train:\n",
    "        f.write(sentence + \"\\n\")\n",
    "with open(f\"../datasets/{save_dir_name_val}/sentences.txt\", \"w\") as f:\n",
    "    for sentence in sentence_list_val:\n",
    "        f.write(sentence + \"\\n\")\n",
    "\n",
    "# write next words into a txt file\n",
    "with open(f\"../datasets/{save_dir_name_train}/next_words.txt\", \"w\") as f:\n",
    "    for next_word in next_word_list_train:\n",
    "        f.write(next_word + \"\\n\")\n",
    "with open(f\"../datasets/{save_dir_name_val}/next_words.txt\", \"w\") as f:\n",
    "    for next_word in next_word_list_val:\n",
    "        f.write(next_word + \"\\n\")\n",
    "# save_json(sentence_list_train, save_dir=f\"../datasets/{save_dir_name_train}\", file_name=\"sentences.txt\")\n",
    "# save_json(sentence_list_val, save_dir=f\"../datasets/{save_dir_name_val}\", file_name=\"sentences.txt\")\n",
    "# save_json(next_word_list_train, save_dir=f\"../datasets/{save_dir_name_train}\", file_name=\"next_words.txt\")\n",
    "# save_json(next_word_list_val, save_dir=f\"../datasets/{save_dir_name_val}\", file_name=\"next_words.txt\")\n",
    "\n",
    "player_words_list_train_with_idx = {f\"{idx}\": player_words for idx, player_words in enumerate(player_words_list_train)}\n",
    "player_words_list_val_with_idx = {f\"{idx}\": player_words for idx, player_words in enumerate(player_words_list_val)}\n",
    "\n",
    "for player_dir_name in player_dir_name_list:\n",
    "    save_json(player_words_list_train_with_idx, save_dir=f\"../players/{save_dir_name_train}/{player_dir_name}\", file_name='player_words.json')\n",
    "    save_json(player_words_list_val_with_idx, save_dir=f\"../players/{save_dir_name_val}/{player_dir_name}\", file_name='player_words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2989b2da8bbeb366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T12:04:37.795574Z",
     "start_time": "2025-02-02T12:04:37.786741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'−' == '-'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuizy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
